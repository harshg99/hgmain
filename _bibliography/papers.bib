@inproceedings{aamas23sociallight,
author = {Goel, Harsh and Zhang, Yifeng and Damani, Mehul and Sartoretti, Guillaume},
title = {SocialLight: Distributed Cooperation Learning towards Network-Wide Traffic Signal Control},
year = {2023},
url = {https://aamas2023.soton.ac.uk/program/accepted-papers/},
abbr = {AAMAS},
keywords = {Adaptive Traffic Signal Control,Autonomous Signal Control; Multi
Agent Reinforcement Learning},
pdf = {AAMAS_2023.pdf},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
booktitle = {Proceedings of the 22nd International Conference on Autonomous Agents and Multiagent Systems},
abstract = {Many recent works have turned to multi-agent reinforcement learn-
ing (MARL) for adaptive traffic signal control to optimize the travel
time of vehicles over large urban networks. However, achieving ef-
fective and scalable cooperation among junctions (agents) remains
an open challenge, as existing methods often rely on extensive, non-
generalizable reward shaping or on non-scalable centralized learn-
ing. To address these problems, we propose a new MARL method for
traffic signal control, SocialLight, which learns cooperative traffic
control policies by distributedly estimating the individual marginal
contribution of agents on their local neighborhood. SocialLight re-
lies on the Asynchronous Actor Critic (A3C) framework, and makes
learning scalable by learning a locally-centralized critic conditioned
over the states and actions of neighboring agents, used by agents
to estimate individual contributions by counterfactual reasoning.
We further introduce important modifications to the advantage
calculation that help stabilize policy updates. These modifications
decouple the impact of the neighborsâ€™ actions on the computed
advantages, thereby reducing the variance in the gradient updates.
We benchmark our trained network against state-of-the-art traf-
fic signal control methods on standard benchmarks in two traffic
simulators, SUMO and CityFlow. Our results show that SocialLight
exhibits improved scalability to larger road networks and better
performance across usual traffic metrics.},
location = {London},
series = {AAMAS '23}
}
@misc{https://doi.org/10.48550/arxiv.2212.08214,
  doi = {10.48550/ARXIV.2212.08214},
  url = {https://arxiv.org/abs/2212.08214},
  abbr = {IROS - AI2R},
  author = {Goel, Harsh and Lipschitz, Laura Jarin and Agarwal, Saurav and Manjanna, Sandeep and Kumar, Vijay},
  keywords = {Robotics (cs.RO), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Reinforcement Learning for Agile Active Target Sensing with a UAV},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International}
}

